{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application\n",
    "We demonstrate an application of our method in recovering an original image from a noisy image. We use MNIST images of handwritten digits to illustrate this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import emachine as EM\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first select a real image from a testing set of MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 (974, 784)\n"
     ]
    }
   ],
   "source": [
    "s0 = np.loadtxt('../MNIST_data/mnist_test.csv',delimiter=',')\n",
    "\n",
    "seq = s0[:,1:] \n",
    "label = s0[:,0]\n",
    "\n",
    "# select only 1 digit\n",
    "digit = 8\n",
    "seq1 = seq[label == digit]\n",
    "print(digit,seq1.shape)\n",
    "\n",
    "# convert to binary\n",
    "seq1 = np.sign(seq1-1.5)\n",
    "\n",
    "# select only one test sample to consider\n",
    "t = 2\n",
    "seq1 = seq1[t]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose the image has `n_hidden` missing pixels. We set their values to be zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select hidden pixels\n",
    "n_hidden = 90\n",
    "hidden = np.random.choice(np.arange(28*28),n_hidden,replace=False)\n",
    "\n",
    "# set value at hidden position to be zero\n",
    "seq_hidden = seq1.copy()\n",
    "seq_hidden[hidden] = 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the original image and the noisy image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x201.6 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx,ny = 2,1\n",
    "fig, ax = plt.subplots(ny,nx,figsize=(nx*3,ny*2.8))\n",
    "ax[0].imshow(seq1.reshape(28,28),interpolation='nearest')\n",
    "ax[1].imshow(seq_hidden.reshape(28,28),interpolation='nearest')\n",
    "\n",
    "ax[0].set_title('original image')\n",
    "ax[1].set_title('noisy image')\n",
    "\n",
    "for i in range(nx):\n",
    "    ax[i].set_axis_off()\n",
    "    \n",
    "plt.tight_layout(h_pad=0.7, w_pad=1.5)\n",
    "#plt.savefig('fig_hidden.pdf', format='pdf', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We aim to reconstruct the missing pixels, and recover the original image. We use images of the same digit from the MNIST training set. Because of the limitation of sample size (n_seq = 5851), compared with number of variables (n_var = 28 x 28 = 784 pixels), we first identify \"conserved\" pixels that have common values for more than 80% of the training samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then find conserved and active pixels from training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5851, 784)\n"
     ]
    }
   ],
   "source": [
    "# load train data\n",
    "s0_train = np.loadtxt('../MNIST_data/mnist_train.csv',delimiter=',')\n",
    "\n",
    "seq_train = s0_train[:,1:] \n",
    "label_train = s0_train[:,0]\n",
    "\n",
    "# select only 1 digit\n",
    "seq1_train = seq_train[label_train == digit] #digit = 8\n",
    "\n",
    "# convert to binary\n",
    "seq1_train = np.sign(seq1_train-1.5)\n",
    "print(seq1_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49 513 562 222\n"
     ]
    }
   ],
   "source": [
    "# find conserved pixels from traing data\n",
    "n,m = seq1_train.shape\n",
    "frequency = [(seq1_train[:,i] == -1).sum()/float(n) for i in range(m)]\n",
    "\n",
    "cols_pos = [i for i in range(m) if frequency[i] < 0.2] # 80% positive\n",
    "cols_neg = [i for i in range(m) if frequency[i] > 0.8] # 80% negative\n",
    "cols_conserved = cols_pos + cols_neg\n",
    "\n",
    "# active pixels\n",
    "cols_active = np.delete(np.arange(0,m),cols_conserved)\n",
    "\n",
    "print(len(cols_pos),len(cols_neg),len(cols_conserved),len(cols_active))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, there are 562 conserved pixels in total, including 49 positive pixels and 513 negative pixels. There are 222 active pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reconstruct the value of conserved hidden pixels (of the test image), we simply set the value of conserved hidden pixels of the test image as the value of corresponding pixels in the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_hidden_active: 26\n"
     ]
    }
   ],
   "source": [
    "hidden_conserved = np.intersect1d(hidden,cols_conserved)\n",
    "hidden_active = np.intersect1d(hidden,cols_active)\n",
    "\n",
    "n_hidden_conserved = len(hidden_conserved)\n",
    "n_hidden_active = len(hidden_active)\n",
    "print('n_hidden_active:',len(hidden_active))\n",
    "\n",
    "## recover hidden\n",
    "seq_recover = seq_hidden.copy()\n",
    "\n",
    "hidden_neg = np.intersect1d(hidden_conserved,cols_neg)\n",
    "hidden_pos = np.intersect1d(hidden_conserved,cols_pos)\n",
    "\n",
    "seq_recover[hidden_neg] = -1.\n",
    "seq_recover[hidden_pos] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, there are `n_hidden_active` (i.e., 26 in this example) hidden pixels that we need to find the values of. We will apply our $\\epsilon$-machine to find the pixel bias and interactions between 222 active pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find pixel bias and interactions of active pixels (from training data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5851, 222)\n",
      "(5851, 24753)\n",
      "0.92 -711.6255597866084\n",
      "0.935 -705.7689428451328\n",
      "0.95 -706.8546800350513\n",
      "0.965 -719.9330903444665\n",
      "0.98 -767.5753296194733\n",
      "optimal eps: 0.935\n"
     ]
    }
   ],
   "source": [
    "seq_train_active = seq1_train[:,cols_active]\n",
    "print((seq_train_active.shape))\n",
    "\n",
    "ops = EM.operators(seq_train_active)\n",
    "print(ops.shape)\n",
    "\n",
    "eps_list = np.linspace(0.92,0.98,5)\n",
    "E_eps = np.zeros(len(eps_list))\n",
    "w_eps = np.zeros((len(eps_list),ops.shape[1]))\n",
    "for i,eps in enumerate(eps_list):    \n",
    "    w_eps[i,:],E_eps[i] = EM.fit(ops,eps=eps,max_iter=100)\n",
    "    print(eps,E_eps[i])\n",
    "    \n",
    "ieps = np.argmax(E_eps)\n",
    "print('optimal eps:',eps_list[ieps])\n",
    "w = w_eps[ieps]\n",
    "#np.savetxt('w.dat',w,fmt='%f')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then apply these to the test image and select the best active hidden pixel vector. This step requires a large computer memory and we perform this procedure by using a computing server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider every possibilities of configurations of the active hidden pixels\n",
    "seq_all = np.asarray(list(itertools.product([1.0, -1.0], repeat=n_hidden_active)))\n",
    "n_possibles = seq_all.shape[0]\n",
    "print('number of possible configs:',n_possibles)\n",
    "\n",
    "active_hidden_indices = np.intersect1d(cols_active,hidden_active,\n",
    "                                       return_indices=True)[1]\n",
    "\n",
    "seq_active = seq1[cols_active]\n",
    "seq_active_possibles = np.tile(seq_active,(n_possibles,1))\n",
    "seq_active_possibles[:,active_hidden_indices] = seq_all\n",
    "\n",
    "# calculate energy of each possible configuration\n",
    "npart = 128   # devide into npart because of PC memory limitation\n",
    "ns = int(n_possibles/npart)\n",
    "energy = np.full(n_possibles,100000.)\n",
    "for i in range(npart):\n",
    "    i1 = int(i*ns)\n",
    "    i2 = int((i+1)*ns)\n",
    "    if i%5 == 0: print('ipart:',i)\n",
    "    ops = EM.operators(seq_active_possibles[i1:i2])\n",
    "    energy[i1:i2] = -ops.dot(w)\n",
    "    \n",
    "# select the best sequence that maximize probability\n",
    "seq_recover[hidden_active] = seq_all[np.argmin(energy)]     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load the computed result from the code above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_recover = np.loadtxt('seq_recover_90.dat')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the image we recovered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaYAAACgCAYAAABHX8iqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAE2lJREFUeJzt3Xu0HWV9xvHvAwRCIBBuYoNgNCAglCKrXFTQ1BLCVSiUOyiXsgCXJYuisIwKVCK1FAu9WLCAIlAwoDUFFgiBKoiCXBRN1aKEEELCLdwToAK+/eN9TzJnzmXvOXvP2e/e5/msddbZe8/tnZl3z2/e9zczWyEEzMzMcrFapwtgZmZW5MBkZmZZcWAyM7OsODCZmVlWHJjMzCwrDkxmZpaVngxMki6V9MV2j9tgPlMkBUlrDDH8V5KmtbocG32Slkt6bxvnt4ekR9o1Pxt7JF0pafYQw46WdPtol6md5PuY2kPSFGAhMC6E8FZnS2NmvUzSlcCTIYQvdLosdei5FpOk1TtdBjPLw1A9GDnphjKOtq4ITJK2lfRDSS+lLrGPF4ZdKekSSbdIWgH8WbmZK+lMSU9JWirpr1KX25aF6Wen19MkPSnpDEnPpmmOL8xnP0k/l/SKpMWSzq2wDo9L2jO9PlfSDZKukfSqpPmS3ifpc2m5iyXtVZj2eEm/SeM+Junk0ryHW7+1JF0o6QlJz6Suy7Wr7oNul7b/ZyT9UtLLkuZIGl8YfpKkRyW9IOlGSZMLw4rbc19Jv077Yomkz6TP/0fSAYVpxklaJmnHQcoyTdKTpbJ9NpVthaQrJG0q6da0nDskbVAY/wZJT6f1uFvSdoVhG0m6KdXRByTNlnRPYfg2kual9XxE0mHt2cL5SNvzLEm/BFZIWkPSZEnflfScpIWSTiuMv7qkWZIWpO39kKTN07APpe34cvr/ofT5EZIeLC33dEk3ptdDfu8Kx5mzJD0NfDN9vr+khxWPcz+RtENh3h+Q9LNUvjnAeIYg6bjSPg+SPiXpd2n68yRNlXRvqifXS1ozjbuBpJvTdnoxvX5XYV7vSXWur15+TdI1heG7pbK/JOkXGmn6IoSQ9R8wDngUmAWsCXwMeBXYOg2/EngZ+DAx0I5Pn81Ow/cGnga2AyYAVwMB2LIwfd+404C3gC+l5e4LvAZsUBj+x2k5OwDPAAelYVPSfNcYYj0eB/ZMr88F3gBmAGsAVxG7AT+flnsSsLAw7X7AVEDAR1OZdmpy/S4GbgQ2BCYCNwF/1+n92oF69DhwPzA5bYvfAKekYR8DlgE7AWsB/wLcXZi2uD2fAvZIrzco7IczgTmFaQ4E5g9RlmnEbphi2e4DNgU2A54FfgZ8IJXnv4FzCuOfkPblWmn/PlwY9u30NwF4P7AYuCcNWye9Pz7Vu53Sem/X6f1Tw75+GNgcWDt9Xx8CziYeQ94LPAbMSON/FpgPbJ2+Y38CbJTqyYvAsWl7HZneb5S276vAVoXlPgAckV4P+b1j1XHm79M+XDvti2eBXYHVgU+m9VgrlXkRcDrx+PCXwJuk49Yg639c3z4v1N8bgfWIx4n/A+5M22F94NfAJ9O4GwGHpPWbCNwAzC3M617gwlSm3YFXgGvSsM2A54nHzdWA6en9JpX3YcUdPgP4UZPjzgFObEMl24N44F2t8Nl1wLnp9ZXAVaVprmRVsPkGhQMxsCXDB6bXKQSXVFl2G6JsFwMXpddTqBaY5hWGHQAsB1ZP7yemeU0aYl5zgZmN1o/4JVsBTC0M/yCFoFfDQWFlHQF+CHxhmHH3oRAA6vxL2/+YwvsLgEvT6yuACwrD1iV+8aek98X68gRwMrBeaf6TiQeq9dL77wBnDlGWaQwMTEcX3n8XuKTw/q8pHBxK85qUyrc+8YD2JumkLQ2fzarAdDil7y/wdQpBbzT/aPJ4ApwKXF1xX59QeL8r8ERpnM8B30yvHwEOHGQ+xwL3lz67Fzguvb4GODu93irt/wmNvndp//8eGF8YfglwXmlZjxBPRD8CLCVdE5CG/YRqgenDhfcPAWcV3n8VuHiIee0IvJheb0EMqBMKw69hVWA6q7yfgNtIQa/KX9NdeZIEXASc0+Qk5wDnt6HbaDKwOITwh8Jni4jRuc/iRtM3OS7A86H/xQuvEQ9USNpV0g9SM/dl4BRg40YrMIRnCq9fB5aFEN4uvKew3H0k3Ze6X14inpH0LXe49duE+EV5KDWtXwK+nz5vu6p1JIRwKzBO0iF1lGcQTxder9yvxG24qFCu5cQzvWId63MIcfsvknSXpA+maZYCPwYOkTSJGHT/o0LZyvWh/L6vLqwu6Sup2+kV4kEYYn3YhHhmP1R9eDewa19dSPXhaOCdFcrZFhXrymXARyX9aYVFlNd7cmm9ZxFbqBBbVgsGmUe/epEUjz3XEltRAEcRTx5eo7nv3XMhhDdKZTyjVMbNUxkmA0tCOtIXylFFs/VrgqSvS1qU6tfdwCTF3P1k4IW0jn3K2/nQ0jrsDvxRxbJWyjHtRWy+/aCZkUMI/0vsgjuy0bgNLAU2l1Qs6xbAkuLihpn+KeBdhfebt1CWa4lN4s1DCOsDlxLPjmojaS3iGfSFwKYhhEnALYXlDrd+y4iVbrsQwqT0t34IYV3qUamOJN8AZtZTnKYtJX6pAJC0DrFLY0l5xBDCAyGEA4F3EFuu1xcGfws4BjgUuDeEMGD6NjiK2E24J7GVNKWv2MBzxDPaoerDYuCuQl2YFEJYN4Rwag3lbKTpupJOFK8GTms0bnGywuvFxNZKcb0nhhD2LQyfOsg8+tWLpHjsuR3YWDGPeCTx+ADNfe/Kx6zFwJdLZZwQQriO+B3fLAXzYjnqcAaxS3PXEMJ6xNYaxPr1FLChpAmF8cv16+rSOqwTQvhK1UJUCUwHAXf0Re2U/PtFSp49laLsOqVp5qXpWvFTYrP4TMWE8jRi19e3m5z+euB4xQsoJhD7mUdqIvGM4Q1JuxAPEnVbk9jP/BzwlqR9iF/qPkOuX2plXgZcJOkdAJI2kzSjprL2qyPJximBulzxwpV9StPMA3aXtFFNZWrGtcRtuGM6ETgf+GkI4fHiSJLWVLxHZP0QwpvE/vW3C6PMJeYKZhLzhnWYSMwRPE88Kz+/b0Bqcf8ncG46890G+ERh2puB90k6Nn2XxknaWdK2NZV1OOXjyTjFCxAeSYn1BaWW9DzggNIJarPuB15RvNhg7dTq3F7Szmn45cB5krZStEOqj7cQt9dRihdQHE7M290MKwPmd4B/IOaS5qXPR/K9uww4JfXKSNI6ihdbTSR2H74FnJbKcTCwywi2QzMmEoPqS5I2pNCiDSEsAh4k1q81U2/BAYVpryHuoxlpG49XvNCjeKLUlCo7eSdikqzPy8QD8yRiHmgPoHxN/fw03YiFEH4PfJzYNbIM+DfgE6lF1sz0twL/TDwze5S4kyF+uav6FPAlSa8SA8D1DcZvWQjhVeKZ4vXExOtRxFZb3/BG63dW+vy+1DS/g3hGVIdyHQE4EfgnYj05H/ie4j1fAKSD/wpior8jQgh3Al8ktkyfIp49HzHE6McCj6dteQqxhdQ3n9fTPN5DDBB1uIrYjbOEuK3vKw3/NLEl9TSxlXEdqS6kurQXcd2WpnH6EvCjrVxXZrOqtbkeMbfyu8Lw+cQ6VPlG5xSwDyDmSxYSjyOXE7cTwD8Sv1+3E082rgDWDiE8D+xPbEU8T7zAZf8QwrLC7K8ltl5vKKUAKn3vQggPEi96+lfi9/xRYq6o7xh4cHr/IjFXWFf9uph4McYyYt36fmn40cR82fPEfTaHVfVrMbE1P4t4Ir2YeGFJ9ZOJZpNRwG9JSb8hhn+agYnC6cBrVRNfdf4B2xLPcge9SKHb/zq5fuU6Qrz4oZwMvQeYVfpsCXBYp7ddm7bB2aRkcA5/xMDzrU6XY7i6QuwmWg7sN8z444jdX7t0uuz+67df5gB/2+75VolkLxLPZACQNF3SjxQvBHglfQHKSfX1gBcqLKMWkv4iNT03IJbzptBDT2fIaP361ZHk8UHel5v2WdSTVqWujxOBf+9gGbZJXVFK3c0nAt/rVHmGUawrmxAvZf/tMOP3jdv19aSbpa7fqZJWk7Q3sYU0t93LqRKYfk7sX0XxZqy5xDzPFiEmyc5i4IUA26fpOu1kYtNyAbE10Ylkb51yWb+VdaRgyiDvizeXvpt4UHq4zoLVTdJJxK6LW0MId3ewKBOJ3TwriN1TXwX+q4PlGUqxrjxHLO9Ww4y/PTF9sLDmctnw3knsCVlOTCGcGkJo+zG+yqMw5hJvPISYkB9PvL79dUnvJ3bllU0n3dXcSSGEvTtdhjpltH7FOtLnIEl/TqzMhwE70z8hPx34cejfb991QgiXERPYnS7HA8R72HK3sq6EEIKkS4ALJD0B/Ip0I3QIYX4afzqxJ+DtQedmoyKEcBPxZuFaVWkx3Ua8KmxaiPd5nEqsSMuBr7HqUkkAJG1NPAO6dsCcrFetrCOFz64A/oZ4tns2cHAI4bHC8BOIF0fY2FKuK58ntvDmEm9UvYvUglJ8ltyxxDN0GwMqPV089SnOCiF8pIlxrwPuDCFc3kL5rMtUrCMziE+G2KP+kllumq0ris+G3COEcMxw41nvGNWfvZi+2qGjtzCrzbw/3FDrTcXlevLoRbv1G77l6eUrpNuv7mV2Yp3qVl6nhTPPGNV6Yt1psONJVzxd3MzMxg4HJjMzy4p/oMqy16ibq45usVbn0ahMvdB1Z1YXt5jMzCwrDkxmZpYVByYzM8uKc0zW9XLM14x2mdqRZ2t1HgPG7/SvbFnXcovJzMyy4sBkZmZZcWAyM7OsOMdk2evFx/fkyNvVcuEWk5mZZcWByczMsuLAZGZmWXGOqWa3La33F8NnTN6x1vnb4Nqd92q9npSmP7z/W9eT3jBWjiduMZmZWVYcmMzMLCsOTGZmlhXnmFpUd5/vSJafSz9xu/TC/TVV68nUOaf0e7/g8Evbvvxeqye9wMeTyC0mMzPLigOTmZllxYHJzMyy4hxTRZ3uA7bGRuPZeo3m2Wo9aTWnVAc/s7D9fDwZnFtMZmaWFQcmMzPLigOTmZllxTmmBtrdB9zongD3Obeey2hH7qNqGTpdT9p939NgnFNqXafrSbdwi8nMzLLiwGRmZllxYDIzs6w4MJmZWVZ88UNJq8nCqg887NbkZJ3qTrI3c2FDqxc7NLoYoVxPBpSJ/stvtLwcbsgtr4P5eDJSbjGZmVlWHJjMzCwrDkxmZpYV55hG2WjfYNeNqt7cWnX8OnJYrd7gWi5Tq/WkXJ7RuDl2wDJm1r7IMa9XjyduMZmZWVYcmMzMLCsOTGZmlhXnmErKfaxV+3B75T6CTurEQ1urKteTBUuHzykNyEE1GL+qhvdNnZ5H7mCs8fFkZNxiMjOzrDgwmZlZVhyYzMwsK84x2ZjXzDPeWs1j1f0suxyelWfWLm4xmZlZVhyYzMwsKw5MZmaWFeeYukwuz7LqJZ24D6pVVX/vaTT495i6T67HE7eYzMwsKw5MZmaWFQcmMzPLinNMmcm1z3c0tZqr6MacUVXldczhWXj+Pab8dOvxxC0mMzPLigOTmZllxYHJzMyy4hxTh3VrH/BoyiFn1DjvVe13c8r3IZWV70sqj78lw2+Tcnmb2YYjmcaGN1Z/T6lVbjGZmVlWHJjMzCwrDkxmZpYV55hKRrtPuLw855zyzG2Uy9TuetIopzTgWXgN7lsayTbMcbvb2OQWk5mZZcWByczMsuLAZGZmWRnzOSbfZ2DNGO16UvU+pnbcg+T7mFrn40l7uMVkZmZZcWAyM7OsODCZmVlWejrHNBr9vY3uO6paBt/XNFDduY9m9lGj+4oaKe/Hco5oKtXmP7CeVCrOoMrbtdF2b/V3s7pNDseTskZl6tbjiVtMZmaWFQcmMzPLigOTmZllpadzTO3QLX2yvawb7qcp15MB+ZkG9x01yilVzWm1Q9Wc0wAz212i7tfq8WSs3CflFpOZmWXFgcnMzLLiwGRmZllxjsmsCVWfXdco/zJg+OEjL9to6YZcn/UGt5jMzCwrDkxmZpYVByYzM8tKT+WY2nGNf7ufVVX38m2gRvfbtOPZeI3yLVXvU6rK9aR+Pp50jltMZmaWFQcmMzPLigOTmZllpadyTO0wVp5FlbNWf39pNO63aVxPOluPmvmtpHZvp7H2+0zN8PFkZNxiMjOzrDgwmZlZVhyYzMwsKw5MZmaWFV/80GHdegNcnXJ4WGgnfphvOK3Wk8G2aaOLTKpehDJguH8ocNT1yvHELSYzM8uKA5OZmWXFgcnMzLLSUzmmcv9qJ25u65U+3m5SNRfSi/VkJDclt5pT6nW9WE+6hVtMZmaWFQcmMzPLigOTmZllpadyTGVjtX+217U7F9IL9aRRvqiZacZ6TqmRXqgn3cItJjMzy4oDk5mZZcWByczMstLTOSbrTTnkQhrlcDpdxk4v36wVbjGZmVlWHJjMzCwrDkxmZpYV55jMRqAXczh+Vp7lwi0mMzPLigOTmZllxYHJzMyy4hyT9Zw6ciWjnX9ptLyq5RnsvqtWn5XnnJTVxS0mMzPLigOTmZllxYHJzMyyohBCp8tgZma2kltMZmaWFQcmMzPLigOTmZllxYHJzMyy4sBkZmZZcWAyM7OsODCZmVlWHJjMzCwrDkxmZpYVByYzM8uKA5OZmWXFgcnMzLLiwGRmZllxYDIzs6w4MJmZWVYcmMzMLCsOTGZmlhUHJjMzy4oDk5mZZcWByczMsuLAZGZmWXFgMjOzrDgwmZlZVv4fcckISE9LTzwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x187.2 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "nx,ny = 3,1\n",
    "nfig = nx*ny\n",
    "fig, ax = plt.subplots(ny,nx,figsize=(nx*2.0,ny*2.6))\n",
    "ax[0].imshow(seq1.reshape(28,28),interpolation='nearest')\n",
    "ax[1].imshow(seq_hidden.reshape(28,28),interpolation='nearest')\n",
    "ax[2].imshow(seq_recover.reshape(28,28),interpolation='nearest')\n",
    "\n",
    "ax[0].set_title('original image')\n",
    "ax[1].set_title('noisy image')\n",
    "ax[2].set_title('recovered image')\n",
    "\n",
    "for i in range(nx):\n",
    "    ax[i].set_axis_off()\n",
    "    \n",
    "label = ['(a)','(b)','(c)','(d)','(e)','(g)','(d)','(h)']\n",
    "xlabel = np.full(nfig,0.0)\n",
    "ylabel = np.full(nfig,1.1)\n",
    "k = 0\n",
    "for i in range(nx):        \n",
    "    ax[i].text(xlabel[k],ylabel[k],label[k],transform=ax[i].transAxes,\n",
    "               va='top',ha='right',fontsize=13)\n",
    "    k += 1\n",
    "        \n",
    "plt.tight_layout(h_pad=0.0, w_pad=0.5)\n",
    "#plt.savefig('fig.pdf', format='pdf', dpi=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recovered image looks like the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
